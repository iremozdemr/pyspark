{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries from pyspark \n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# set values for spark configuration\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"tranformations\")\n",
    "\n",
    "# get (if already running) or create a spark context\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:289"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
     ]
    }
   ],
   "source": [
    "mapped_rdd = rdd.map(lambda x: x * x)\n",
    "print(mapped_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [4], [9], [16], [25], [36], [49], [64], [81], [100]]\n"
     ]
    }
   ],
   "source": [
    "mapped_rdd = rdd.map(lambda x: [x * x])\n",
    "print(mapped_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "filtered_rdd = rdd.filter(lambda x: x % 2 == 0)\n",
    "print(filtered_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 4, 3, 9, 4, 16, 5, 25, 6, 36, 7, 49, 8, 64, 9, 81, 10, 100]\n"
     ]
    }
   ],
   "source": [
    "flatmapped_rdd = rdd.flatMap(lambda x: [x, x * x])\n",
    "print(flatmapped_rdd.collect())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
     ]
    }
   ],
   "source": [
    "flatmapped_rdd = rdd.flatMap(lambda x: [x * x])\n",
    "print(flatmapped_rdd.collect())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 5, 8]\n"
     ]
    }
   ],
   "source": [
    "sampled_rdd = rdd.sample(withReplacement=False, fraction=0.3, seed=42)\n",
    "print(sampled_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "another_rdd = sc.parallelize([11, 12, 13, 14])\n",
    "union_rdd = rdd.union(another_rdd)\n",
    "print(union_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "rdd_with_duplicates = sc.parallelize([1, 2, 2, 3, 3, 3, 4, 5, 5, 6])\n",
    "distinct_rdd = rdd_with_duplicates.distinct()\n",
    "print(distinct_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([\n",
    "    (\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4), (\"c\", 5), (\"c\", 6)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', [1, 3]), ('b', [2, 4]), ('c', [5, 6])]\n",
      "a [1, 3]\n",
      "b [2, 4]\n",
      "c [5, 6]\n",
      "['a', [1, 3]]\n",
      "['b', [2, 4]]\n",
      "['c', [5, 6]]\n"
     ]
    }
   ],
   "source": [
    "grouped_rdd = rdd.groupByKey()\n",
    "\n",
    "print([(k, list(v)) for k,v in grouped_rdd.collect()])\n",
    "\n",
    "for k,v in grouped_rdd.collect():\n",
    "    print(k,list(v))\n",
    "\n",
    "for k,v in grouped_rdd.collect():\n",
    "    print([k,list(v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 4), ('b', 6), ('c', 11)]\n"
     ]
    }
   ],
   "source": [
    "reduced_rdd = rdd.reduceByKey(lambda x,y : x + y)\n",
    "print(reduced_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1), ('a', 3), ('b', 2), ('b', 4), ('c', 5), ('c', 6)]\n"
     ]
    }
   ],
   "source": [
    "sorted_rdd = rdd.sortByKey(ascending=True)\n",
    "print(sorted_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', (2, 'valueforb')), ('b', (4, 'valueforb')), ('c', (5, 'valueforc')), ('c', (6, 'valueforc')), ('a', (1, 'valuefora')), ('a', (3, 'valuefora'))]\n"
     ]
    }
   ],
   "source": [
    "rdd2 = sc.parallelize([\n",
    "    (\"a\", \"valuefora\"), (\"b\", \"valueforb\"), (\"c\", \"valueforc\")\n",
    "])\n",
    "\n",
    "joined_rdd = rdd.join(rdd2)\n",
    "print(joined_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b [2, 4] [200]\n",
      "c [5, 6] [300]\n",
      "a [1, 3] [100, 400]\n"
     ]
    }
   ],
   "source": [
    "rdd3 = sc.parallelize([\n",
    "    (\"a\", 100), (\"b\", 200), (\"c\", 300), (\"a\", 400)\n",
    "])\n",
    "\n",
    "cogroup_rdd = rdd.cogroup(rdd3)\n",
    "\n",
    "for k, (v1, v2) in cogroup_rdd.collect():\n",
    "    print(k, list(v1), list(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('a', 1), 'x'), (('a', 1), 'y'), (('b', 2), 'x'), (('b', 2), 'y'), (('a', 3), 'x'), (('a', 3), 'y'), (('b', 4), 'x'), (('b', 4), 'y'), (('c', 5), 'x'), (('c', 5), 'y'), (('c', 6), 'x'), (('c', 6), 'y')]\n"
     ]
    }
   ],
   "source": [
    "rdd4 = sc.parallelize([\"x\", \"y\"])\n",
    "\n",
    "cartesian_rdd = rdd.cartesian(rdd4)\n",
    "print(cartesian_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sc\n",
    "except NameError:\n",
    "    print(\"spark context does not context exist - nothing to stop\")\n",
    "else:\n",
    "    sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_kernel",
   "language": "python",
   "name": "myproject_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
