{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "window functions operate on a group of rows referred to as a window and calculate a return value for each row based on the group of rows \n",
    "\n",
    "window functions are useful for processing tasks such as \n",
    "- calculating a moving average\n",
    "- computing a cumulative statistic\n",
    "- accessing the value of rows given the relative position of the current row.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ranking functions:\n",
    "- RANK\n",
    "- DENSE_RANK\n",
    "- PERCENT_RANK\n",
    "- NTILE\n",
    "- ROW_NUMBER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analytic functions:\n",
    "- CUME_DIST\n",
    "- LAG\n",
    "- LEAD\n",
    "- NTH_VALUE\n",
    "- FIRST_VALUE\n",
    "- LAST_VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggregate functions:\n",
    "- MAX\n",
    "- MIN\n",
    "- COUNT\n",
    "- SUM\n",
    "- AVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nulls_option:\n",
    "\n",
    "specifies whether or not to skip null values when evaluating the window function\n",
    "\n",
    "RESPECT NULLS means not skipping null values \n",
    "\n",
    "while IGNORE NULLS means skipping\n",
    "\n",
    "if not specified the default is RESPECT NULLS\n",
    "\n",
    "only LAG | LEAD | NTH_VALUE | FIRST_VALUE | LAST_VALUE can be used with IGNORE NULLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "from pyspark.sql import SparkSession, functions, Row\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.functions import col, lit, concat, lower, upper, substring, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/25 14:03:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"Lisa\", \"Sales\", 10000, 35),\n",
    "    (\"Evan\", \"Sales\", 32000, 38),\n",
    "    (\"Fred\", \"Engineering\", 21000, 28),\n",
    "    (\"Alex\", \"Sales\", 30000, 33),\n",
    "    (\"Tom\", \"Engineering\", 23000, 33),\n",
    "    (\"Jane\", \"Marketing\", 29000, 28),\n",
    "    (\"Jeff\", \"Marketing\", 35000, 38),\n",
    "    (\"Paul\", \"Engineering\", 29000, 23),\n",
    "    (\"Chloe\", \"Engineering\", 23000, 25)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"name\", \"dept\", \"salary\", \"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>dept</th><th>salary</th><th>age</th></tr>\n",
       "<tr><td>Lisa</td><td>Sales</td><td>10000</td><td>35</td></tr>\n",
       "<tr><td>Evan</td><td>Sales</td><td>32000</td><td>38</td></tr>\n",
       "<tr><td>Fred</td><td>Engineering</td><td>21000</td><td>28</td></tr>\n",
       "<tr><td>Alex</td><td>Sales</td><td>30000</td><td>33</td></tr>\n",
       "<tr><td>Tom</td><td>Engineering</td><td>23000</td><td>33</td></tr>\n",
       "<tr><td>Jane</td><td>Marketing</td><td>29000</td><td>28</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>35000</td><td>38</td></tr>\n",
       "<tr><td>Paul</td><td>Engineering</td><td>29000</td><td>23</td></tr>\n",
       "<tr><td>Chloe</td><td>Engineering</td><td>23000</td><td>25</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----------+------+---+\n",
       "| name|       dept|salary|age|\n",
       "+-----+-----------+------+---+\n",
       "| Lisa|      Sales| 10000| 35|\n",
       "| Evan|      Sales| 32000| 38|\n",
       "| Fred|Engineering| 21000| 28|\n",
       "| Alex|      Sales| 30000| 33|\n",
       "|  Tom|Engineering| 23000| 33|\n",
       "| Jane|  Marketing| 29000| 28|\n",
       "| Jeff|  Marketing| 35000| 38|\n",
       "| Paul|Engineering| 29000| 23|\n",
       "|Chloe|Engineering| 23000| 25|\n",
       "+-----+-----------+------+---+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>dept</th><th>salary</th><th>rank</th></tr>\n",
       "<tr><td>Fred</td><td>Engineering</td><td>21000</td><td>1</td></tr>\n",
       "<tr><td>Tom</td><td>Engineering</td><td>23000</td><td>2</td></tr>\n",
       "<tr><td>Chloe</td><td>Engineering</td><td>23000</td><td>2</td></tr>\n",
       "<tr><td>Paul</td><td>Engineering</td><td>29000</td><td>4</td></tr>\n",
       "<tr><td>Jane</td><td>Marketing</td><td>29000</td><td>1</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>35000</td><td>2</td></tr>\n",
       "<tr><td>Lisa</td><td>Sales</td><td>10000</td><td>1</td></tr>\n",
       "<tr><td>Alex</td><td>Sales</td><td>30000</td><td>2</td></tr>\n",
       "<tr><td>Evan</td><td>Sales</td><td>32000</td><td>3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----------+------+----+\n",
       "| name|       dept|salary|rank|\n",
       "+-----+-----------+------+----+\n",
       "| Fred|Engineering| 21000|   1|\n",
       "|  Tom|Engineering| 23000|   2|\n",
       "|Chloe|Engineering| 23000|   2|\n",
       "| Paul|Engineering| 29000|   4|\n",
       "| Jane|  Marketing| 29000|   1|\n",
       "| Jeff|  Marketing| 35000|   2|\n",
       "| Lisa|      Sales| 10000|   1|\n",
       "| Alex|      Sales| 30000|   2|\n",
       "| Evan|      Sales| 32000|   3|\n",
       "+-----+-----------+------+----+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT name, dept, salary, RANK() OVER (PARTITION BY dept ORDER BY salary) AS rank FROM employees;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>dept</th><th>salary</th><th>rank</th></tr>\n",
       "<tr><td>Fred</td><td>Engineering</td><td>21000</td><td>1</td></tr>\n",
       "<tr><td>Tom</td><td>Engineering</td><td>23000</td><td>2</td></tr>\n",
       "<tr><td>Chloe</td><td>Engineering</td><td>23000</td><td>2</td></tr>\n",
       "<tr><td>Paul</td><td>Engineering</td><td>29000</td><td>3</td></tr>\n",
       "<tr><td>Jane</td><td>Marketing</td><td>29000</td><td>1</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>35000</td><td>2</td></tr>\n",
       "<tr><td>Lisa</td><td>Sales</td><td>10000</td><td>1</td></tr>\n",
       "<tr><td>Alex</td><td>Sales</td><td>30000</td><td>2</td></tr>\n",
       "<tr><td>Evan</td><td>Sales</td><td>32000</td><td>3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----------+------+----+\n",
       "| name|       dept|salary|rank|\n",
       "+-----+-----------+------+----+\n",
       "| Fred|Engineering| 21000|   1|\n",
       "|  Tom|Engineering| 23000|   2|\n",
       "|Chloe|Engineering| 23000|   2|\n",
       "| Paul|Engineering| 29000|   3|\n",
       "| Jane|  Marketing| 29000|   1|\n",
       "| Jeff|  Marketing| 35000|   2|\n",
       "| Lisa|      Sales| 10000|   1|\n",
       "| Alex|      Sales| 30000|   2|\n",
       "| Evan|      Sales| 32000|   3|\n",
       "+-----+-----------+------+----+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT name, dept, salary, DENSE_RANK() OVER (PARTITION BY dept ORDER BY salary) AS dense_rank FROM employees;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>dept</th><th>salary</th><th>cume_dist</th></tr>\n",
       "<tr><td>Fred</td><td>Engineering</td><td>21000</td><td>0.25</td></tr>\n",
       "<tr><td>Tom</td><td>Engineering</td><td>23000</td><td>0.75</td></tr>\n",
       "<tr><td>Chloe</td><td>Engineering</td><td>23000</td><td>0.75</td></tr>\n",
       "<tr><td>Paul</td><td>Engineering</td><td>29000</td><td>1.0</td></tr>\n",
       "<tr><td>Jane</td><td>Marketing</td><td>29000</td><td>0.5</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>35000</td><td>1.0</td></tr>\n",
       "<tr><td>Lisa</td><td>Sales</td><td>10000</td><td>0.3333333333333333</td></tr>\n",
       "<tr><td>Alex</td><td>Sales</td><td>30000</td><td>0.6666666666666666</td></tr>\n",
       "<tr><td>Evan</td><td>Sales</td><td>32000</td><td>1.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----------+------+------------------+\n",
       "| name|       dept|salary|         cume_dist|\n",
       "+-----+-----------+------+------------------+\n",
       "| Fred|Engineering| 21000|              0.25|\n",
       "|  Tom|Engineering| 23000|              0.75|\n",
       "|Chloe|Engineering| 23000|              0.75|\n",
       "| Paul|Engineering| 29000|               1.0|\n",
       "| Jane|  Marketing| 29000|               0.5|\n",
       "| Jeff|  Marketing| 35000|               1.0|\n",
       "| Lisa|      Sales| 10000|0.3333333333333333|\n",
       "| Alex|      Sales| 30000|0.6666666666666666|\n",
       "| Evan|      Sales| 32000|               1.0|\n",
       "+-----+-----------+------+------------------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT name, dept, salary, CUME_DIST() OVER (PARTITION BY dept ORDER BY salary) AS cume_dist FROM employees;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>dept</th><th>salary</th><th>row_number</th></tr>\n",
       "<tr><td>Fred</td><td>Engineering</td><td>21000</td><td>1</td></tr>\n",
       "<tr><td>Tom</td><td>Engineering</td><td>23000</td><td>2</td></tr>\n",
       "<tr><td>Chloe</td><td>Engineering</td><td>23000</td><td>3</td></tr>\n",
       "<tr><td>Paul</td><td>Engineering</td><td>29000</td><td>4</td></tr>\n",
       "<tr><td>Jane</td><td>Marketing</td><td>29000</td><td>1</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>35000</td><td>2</td></tr>\n",
       "<tr><td>Lisa</td><td>Sales</td><td>10000</td><td>1</td></tr>\n",
       "<tr><td>Alex</td><td>Sales</td><td>30000</td><td>2</td></tr>\n",
       "<tr><td>Evan</td><td>Sales</td><td>32000</td><td>3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----------+------+----------+\n",
       "| name|       dept|salary|row_number|\n",
       "+-----+-----------+------+----------+\n",
       "| Fred|Engineering| 21000|         1|\n",
       "|  Tom|Engineering| 23000|         2|\n",
       "|Chloe|Engineering| 23000|         3|\n",
       "| Paul|Engineering| 29000|         4|\n",
       "| Jane|  Marketing| 29000|         1|\n",
       "| Jeff|  Marketing| 35000|         2|\n",
       "| Lisa|      Sales| 10000|         1|\n",
       "| Alex|      Sales| 30000|         2|\n",
       "| Evan|      Sales| 32000|         3|\n",
       "+-----+-----------+------+----------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT name, dept, salary, ROW_NUMBER() OVER (PARTITION BY dept ORDER BY salary) AS row_number FROM employees;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>salary</th><th>previous_salary</th><th>next_salary</th></tr>\n",
       "<tr><td>Fred</td><td>21000</td><td>0</td><td>23000</td></tr>\n",
       "<tr><td>Tom</td><td>23000</td><td>21000</td><td>23000</td></tr>\n",
       "<tr><td>Chloe</td><td>23000</td><td>23000</td><td>29000</td></tr>\n",
       "<tr><td>Paul</td><td>29000</td><td>23000</td><td>0</td></tr>\n",
       "<tr><td>Jane</td><td>29000</td><td>0</td><td>35000</td></tr>\n",
       "<tr><td>Jeff</td><td>35000</td><td>29000</td><td>0</td></tr>\n",
       "<tr><td>Lisa</td><td>10000</td><td>0</td><td>30000</td></tr>\n",
       "<tr><td>Alex</td><td>30000</td><td>10000</td><td>32000</td></tr>\n",
       "<tr><td>Evan</td><td>32000</td><td>30000</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+------+---------------+-----------+\n",
       "| name|salary|previous_salary|next_salary|\n",
       "+-----+------+---------------+-----------+\n",
       "| Fred| 21000|              0|      23000|\n",
       "|  Tom| 23000|          21000|      23000|\n",
       "|Chloe| 23000|          23000|      29000|\n",
       "| Paul| 29000|          23000|          0|\n",
       "| Jane| 29000|              0|      35000|\n",
       "| Jeff| 35000|          29000|          0|\n",
       "| Lisa| 10000|              0|      30000|\n",
       "| Alex| 30000|          10000|      32000|\n",
       "| Evan| 32000|          30000|          0|\n",
       "+-----+------+---------------+-----------+"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LAG(column,offset,default_value)\n",
    "# LEAD(column,offset,default_value)\n",
    "\n",
    "spark.sql(\"SELECT name, salary, LAG(salary, 1, 0) OVER (PARTITION BY dept ORDER BY salary) AS previous_salary, LEAD(salary, 1, 0) OVER (PARTITION BY dept ORDER BY salary) AS next_salary FROM employees;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>dept</th><th>salary</th><th>first_salary</th></tr>\n",
       "<tr><td>Fred</td><td>Engineering</td><td>21000</td><td>21000</td></tr>\n",
       "<tr><td>Tom</td><td>Engineering</td><td>23000</td><td>21000</td></tr>\n",
       "<tr><td>Chloe</td><td>Engineering</td><td>23000</td><td>21000</td></tr>\n",
       "<tr><td>Paul</td><td>Engineering</td><td>29000</td><td>21000</td></tr>\n",
       "<tr><td>Jane</td><td>Marketing</td><td>29000</td><td>29000</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>35000</td><td>29000</td></tr>\n",
       "<tr><td>Lisa</td><td>Sales</td><td>10000</td><td>10000</td></tr>\n",
       "<tr><td>Alex</td><td>Sales</td><td>30000</td><td>10000</td></tr>\n",
       "<tr><td>Evan</td><td>Sales</td><td>32000</td><td>10000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----------+------+------------+\n",
       "| name|       dept|salary|first_salary|\n",
       "+-----+-----------+------+------------+\n",
       "| Fred|Engineering| 21000|       21000|\n",
       "|  Tom|Engineering| 23000|       21000|\n",
       "|Chloe|Engineering| 23000|       21000|\n",
       "| Paul|Engineering| 29000|       21000|\n",
       "| Jane|  Marketing| 29000|       29000|\n",
       "| Jeff|  Marketing| 35000|       29000|\n",
       "| Lisa|      Sales| 10000|       10000|\n",
       "| Alex|      Sales| 30000|       10000|\n",
       "| Evan|      Sales| 32000|       10000|\n",
       "+-----+-----------+------+------------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT name, dept, salary, FIRST_VALUE(salary) OVER (PARTITION BY dept ORDER BY salary) AS first_salary FROM employees;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>dept</th><th>salary</th><th>last_salary</th></tr>\n",
       "<tr><td>Fred</td><td>Engineering</td><td>21000</td><td>29000</td></tr>\n",
       "<tr><td>Tom</td><td>Engineering</td><td>23000</td><td>29000</td></tr>\n",
       "<tr><td>Chloe</td><td>Engineering</td><td>23000</td><td>29000</td></tr>\n",
       "<tr><td>Paul</td><td>Engineering</td><td>29000</td><td>29000</td></tr>\n",
       "<tr><td>Jane</td><td>Marketing</td><td>29000</td><td>35000</td></tr>\n",
       "<tr><td>Jeff</td><td>Marketing</td><td>35000</td><td>35000</td></tr>\n",
       "<tr><td>Lisa</td><td>Sales</td><td>10000</td><td>32000</td></tr>\n",
       "<tr><td>Alex</td><td>Sales</td><td>30000</td><td>32000</td></tr>\n",
       "<tr><td>Evan</td><td>Sales</td><td>32000</td><td>32000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+-----------+------+-----------+\n",
       "| name|       dept|salary|last_salary|\n",
       "+-----+-----------+------+-----------+\n",
       "| Fred|Engineering| 21000|      29000|\n",
       "|  Tom|Engineering| 23000|      29000|\n",
       "|Chloe|Engineering| 23000|      29000|\n",
       "| Paul|Engineering| 29000|      29000|\n",
       "| Jane|  Marketing| 29000|      35000|\n",
       "| Jeff|  Marketing| 35000|      35000|\n",
       "| Lisa|      Sales| 10000|      32000|\n",
       "| Alex|      Sales| 30000|      32000|\n",
       "| Evan|      Sales| 32000|      32000|\n",
       "+-----+-----------+------+-----------+"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT name, dept, salary, LAST_VALUE(salary) OVER (PARTITION BY dept ORDER BY salary ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_salary FROM employees;\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_kernel",
   "language": "python",
   "name": "myproject_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
